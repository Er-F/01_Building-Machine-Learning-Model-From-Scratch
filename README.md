# Machine Learning Model (From Scratch): Entropy and Gini-Index Functions

This repository contains a project developed during my university studies, focusing on creating an ML model from scratch based on entropy and Gini-index evaluations. The project includes functions to compute these metrics, evaluate the information gain for features in a dataset, and compare model performance.

## Overview

In this project, you will find:

1. **Entropy Calculation**: Functions to calculate entropy from a probability distribution.
2. **Gini-Index Calculation**: Functions to compute the Gini-index for a probability distribution.
3. **Information Gain**: Methods to calculate the information gain for each feature in a dataset.
4. **Probability Distribution**: Functions to determine the probability distribution of classification labels.
5. **Model Comparison**: Code to compare various machine learning models and visualize their performance.
6. **Confusion Matrix and Heatmap**: Evaluation of model performance using confusion matrices and heatmaps.

## Output Example 

![image](https://github.com/user-attachments/assets/d2048eb6-d249-44ef-aca6-d5af73920c5d)

## Model Comparison
The project includes code to compare various machine learning models, including:

- Linear Regression
- Support Vector Machine (SVM)
- Multi-Layer Perceptron (MLP)
- K-Nearest Neighbors (KNN)
- XGBoost
- Decision Tree
- ElasticNet
- Random Forest

The models are trained, tested, and their predictions are visualized for easy comparison. The best models are identified based on their accuracy scores.

## Visualization

The project uses Seaborn to create bar charts and heatmaps for visualizing model performance and confusion matrices. This helps in understanding the strengths and weaknesses of each model.

## Conclusion

This project provides essential tools for calculating entropy, Gini-index, and information gain, which are crucial for various machine learning tasks. It also includes methods for comparing different machine learning models and visualizing their performance. Feel free to explore the code and use these functions in your own projects to enhance your machine learning models.



